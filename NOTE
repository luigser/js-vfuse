Nodejs version (it works for browser but nodejs)
v12.16.3
PASS TO v14

/* RUN IPFS CLUSTER */
ipfs-cluster-service --loglevel info,cluster:debug,pintracker:debug daemon

USE ipfs-cluster_service for config cluster


TO START WEBRTC SIGNAL SERVER
node node_modules\libp2p-webrtc-star\src\sig-server\bin.js --port=2000


npm install ipfs-swarm-key-gen -g

//Profile ids
//WITH NODE API
12D3KooWHAe9ih2WHHsttbzyjfvWqCU9xXroiS8rb2BfqA495EdL //ALLINONE
12D3KooWCDmRPNZvne44L2ARDbrQB7X89c8g7XHjJqmPPUvA5vCr //ALLINONE
12D3KooWLGqTJsVQGMNrnLbRCGqPhHJrG9BLqA4xYLdWr3kCQfFq //SURFACE
//REGULAR
//Chrome
//ALLINONE
12D3KooWSz8xCReetryX7vpE7VNDDAxWtyh1pe6pWZ33nyoQzo8D
//SURFACE
12D3KooWEXq1trVMayJaFjnutSciyn3HgDrTu3NrKWVVTNpRo5Xa
//Firefox
//ALLINONE
12D3KooWEyShEo5ycTjet7AuJGFUWBryL9b48FhJVsRUZ4v61jE6
//SURFACE
12D3KooWJwkjUvWWu9vdzyE1d3CtkzXsmGDXaM8LXuCq6LjunWak

//Domande e note

Il workflow manager deve usare una factory per il runtime
Ogni runtime deve implementare il meccanismo di parsing per i jobs e dati

1) utilizzare un oggetto "VFuse.NOME_FUNZIONE"
    L'idea è passare da python a javascript per recuperare dati da IPFS/HTTP utilizzando funzioni scritte in Python ma implementate in javascript
        ESEMPIO:
        def map(input)
           ...
           print(output)
        def reduce(input)
           ....
           print(output)

        input = 'ipfs/HASH' //l'input potrebbe essere definito dall'esterno con un input box e qualcosa del genere
        for chank in range(input_size)
           data_chunk = VFuse.getBytes(input, chank, 1024)
           VFuse.createJob(map, data_chunk, [])
           VFuse.createJob(reduce, data_chunk, [map])


    - esiste un modo per mappare funzioni da un liguaggio ad un altro( design pattern, DSL o qualcosa del genere?)
        - VFUSE.getData(url, return_type) //quando non si vogliono definire i dati direttamente nel codice; return_type devev essere gestito dal manager


input = [[2, 0], [0, 2], [4, 1], [2, 2]]
OR
input = VFuse.getData("http://IP/ipfs/CID", start, end, VFuse.ArrayString) // Worker -> factory -> getData per Python

def partion2()
   return VFuse.getData("http://IP/ipfs/CID", start, end, VFuse.ArrayString)

def partition(input)
   return 4 elementi [2, 0], [0, 2], [4, 1], [2, 2]

def task(data)
   data[0] + data[1]


def somma(data)
   somma = 0
   for data 1...data.length
      somma += data[i]

VFuse.addJobsInput(partition, input) //workflow -> /data/input 1,2,3,4 ->  [2, 0], [0, 2], [4, 1], [2, 2]  // corrisponde a un file di result
VFuse.addJobs(task,  [partition])
VFuse.addJobs(somma, [task])

Datalet che filtrano big data in parallelo


//JAVASCRIPT
let chunck = 1000
for(let i=0; i < input.length; i+=chunk){
   let chunck_lenght = 1000
   if(i + chunck > input.length)
      chunk_length = chunk - ((i + chunk) - input.lenght)
   VFuse.addJob()
}

MAP-REDUCE EXAMPLE

let input = "Contrary to popular belief, Lorem Ipsum is not simply random text.\n" +
        "It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old.\n" +
        "Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur,\n" +
        "from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source.\n" +
        " Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero,\n" +
        " written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum," +
        "\"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32."
function map(data){
   let tokens = []
   data.split(/\W+/).map(word => tokens.push({ word : word , count : 1 }))
   return tokens
}

function reduce(data){
   let reduced = new Map()
   data.map( entry => reduced.set(entry.word, reduced.has(entry.word) ? reduced.get(entry.word) + 1 : 1))
   return reduced
}

function combine(data){
   let result = new Map()
   for(let d of data)
      result.set(d.key, result.has(d.key) ? result.get(d.key) + d.value : d.value)
   return result
}

function getMaxOccurenceWord(data){
    let max = data[0]
    for(let entry of data){
        if(entry.value > max.value)
           max = entry
    }
    return max
}

input = input.split("\n")
let reduced_results = []
for (let row in input){
   let mapped = await VFuse.addJob(map, [], input[row])
   let reduced = await VFuse.addJob(reduce, [mapped])
   reduced_results.push(mapped)
}

let combine_job_id = await VFuse.addJob(combine, ['reduce'])//wait for all reduce results and call combine
await VFuse.addJob(getMaxOccurenceWord, [combine_job_id])




//TODO note

Quando si crea un nuovo repository, con un nuovo id, si ottiene un nuovo peer id

Lettura di file
Su browser è possibile utilizzare solo HTTP E WEB SOCKET
per leggere un parte di un file si può usare l'header range che deve essere supportato dal server
var xmlhttp=new XMLHttpRequest();
xmlhttp.open("GET","data.dat",false);
xmlhttp.setRequestHeader("Range", "bytes=100-200");
xmlhttp.send();
console.info(xmlhttp); //--> returns only the partial content

//TODO
Indicizzare i workflows in locale
    -quando un workflow è molto grosso capita che la filtering impieghi molto tempo per ottenere i risultati

//TODO NEW
    - TIMEOUT sull'esecuzione del job ( evitare overload)
    - meccanismo per la REPUTATION
    - meccanismo per il CHECKING dei risultati (possibile accumulare i risultati di più esecuzioni e confrontarli)
    - limitare il numero di workflow su cui lavorare in un feterminato momento
    - marcare i job di OUTPUT (invorsimile in alcuni casi recuperare l'output dal DAG
    - prevedere un meccanismo per registrare le funzioni senza includere il codice in ogni job ma recuperandolo dal workflow
    - definire un meccanismo che consenta ai job di ricevere uno stream senza diventare COMPLETED

