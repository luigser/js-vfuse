Nodejs version (it works for browser but nodejs)
v12.16.3
PASS TO v14

/* RUN IPFS CLUSTER */
ipfs-cluster-service --loglevel info,cluster:debug,pintracker:debug daemon

USE ipfs-cluster_service for config cluster


TO START WEBRTC SIGNAL SERVER
node node_modules\libp2p-webrtc-star\src\sig-server\bin.js --port=2000


npm install ipfs-swarm-key-gen -g

12D3KooWAaerNGh5QT5VG2wszDGCKVPMpddXUzKSTSkwTHwXL3xW
QmTPeYtDJf61yRd6so153qSzvkPiD49af7367Wiv8QzQxS
12D3KooWJ1iCEaDuU1DLJcag2An37DBQbcukWEVRFJsvRSLcGSFd


//Domande e note

Il workflow manager deve usare una factory per il runtime
Ogni runtime deve implementare il meccanismo di parsing per i jobs e dati

1) utilizzare un oggetto "VFuse.NOME_FUNZIONE"
    L'idea è passare da python a javascript per recuperare dati da IPFS/HTTP utilizzando funzioni scritte in Python ma inplementate in javascript
        ESEMPIO:
        def map(input)
           ...
           print(output)
        def reduce(input)
           ....
           print(output)

        input = 'ipfs/HASH' //l'input potrebbe essere definito dall'esterno con un input box e qualcosa del genere
        for chank in range(input_size)
           data_chunk = VFuse.getBytes(input, chank, 1024)
           VFuse.createJob(map, data_chunk, [])
           VFuse.createJob(reduce, data_chunk, [map])


    - esiste un modo per mappare funzioni da un liguaggio ad un altro( design pattern, DSL o qualcosa del genere?)
        - VFUSE.getData(url, return_type) //quando non si vogliono definire i dati direttamente nel codice; return_type devev essere gestito dal manager


input = [[2, 0], [0, 2], [4, 1], [2, 2]]
OR
input = VFuse.getData("http://IP/ipfs/CID", start, end, VFuse.ArrayString) // Worker -> factory -> getData per Python

def partion2()
   return VFuse.getData("http://IP/ipfs/CID", start, end, VFuse.ArrayString)

def partition(input)
   return 4 elementi [2, 0], [0, 2], [4, 1], [2, 2]

def task(data)
   data[0] + data[1]


def somma(data)
   somma = 0
   for data 1...data.length
      somma += data[i]

VFuse.addJobsInput(partition, input) //workflow -> /data/input 1,2,3,4 ->  [2, 0], [0, 2], [4, 1], [2, 2]  // corrisponde a un file di result
VFuse.addJobs(task,  [partition])
VFuse.addJobs(somma, [task])

Datalet che filtrano big data in parallelo


//JAVASCRIPT
let chunck = 1000
for(let i=0; i < input.length; i+=chunk){
   let chunck_lenght = 1000
   if(i + chunck > input.length)
      chunk_length = chunk - ((i + chunk) - input.lenght)
   VFuse.addJob()
}

MAP-REDUCE

let input = "VERY_BIG_TEXT"
//let input = VFuse.getData('http://GATEWAY/ipfs/CID', start, end, VFuse.DATA.Type.String)

let input = "Contrary to popular belief, Lorem Ipsum is not simply random text.\n" +
        "It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old.\n" +
        "Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur,\n" +
        "from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source.\n" +
        " Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero,\n" +
        " written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum," +
        "\"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32."

function map(data){
   let tokens = []
   data.split(/\W+/).map(word => token.push({ word : word , count : 1 }))
   return token
}

function reduce(data){
   let reduced = new Map()
   data.map( entry => reduced.set(entry.word, reduced.has(entry.word) ? entry.get(entry.word) + 1 : 1))
   return reduced
}

function combine(data){
   let result = new Map()
   data.map( entry => reduced.set(entry.word, result.has(entry.word) ? entry.get(entry.word) + 1 : 1))
   return result
}

let mapped = await Promise.all(input.split("\n").map(async row => await VFuse.addJob(map, row)))
debugger
let reduced = await Promise.all(mapped.map(async m => await VFuse.addJob(reduce, m, ['map'])))
debugger
let result = await VFuse.addJob(combine, reduced, ['reduce'])


//Todo
SI VA IN ERRORE QUANDO IL PROFILO GIà ESISTE E SI CERCA DI CREARNE UN ALTRO.
QUANDO SI SALVA IL RPOFILO QUESTO VIENE APPESO A QUELLO PRECEDENTE
L'ERRORE è DOCUTO ALLA SOVREAPPOSOZIONE NEL DAG DEI BLOCCHI
